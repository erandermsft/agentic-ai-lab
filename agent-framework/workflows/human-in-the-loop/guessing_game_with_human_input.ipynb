{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e35836a1",
   "metadata": {},
   "source": [
    "# Human-in-the-Loop Guessing Game\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates **human-in-the-loop (HITL)** workflows - a pattern where an AI agent alternates turns with a human to collaboratively solve a problem. This interactive guessing game showcases:\n",
    "\n",
    "1. **RequestInfoExecutor**: Pause workflow for human input\n",
    "2. **Request/Response Correlation**: Match human replies to specific requests\n",
    "3. **Structured Agent Output**: Enforce JSON schema with `response_format`\n",
    "4. **Turn-Based Coordination**: Orchestrate agent ‚Üî human cycles\n",
    "5. **Event-Driven Streaming**: Real-time interaction via workflow events\n",
    "\n",
    "### Game Flow:\n",
    "\n",
    "```\n",
    "Start Game\n",
    "    ‚Üì\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  Agent Makes Guess (1-10)   ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "    ‚Üì\n",
    "TurnManager requests human feedback\n",
    "    ‚Üì\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  Human Responds:            ‚îÇ\n",
    "‚îÇ  ‚Ä¢ \"higher\" - guess low     ‚îÇ\n",
    "‚îÇ  ‚Ä¢ \"lower\" - guess high     ‚îÇ\n",
    "‚îÇ  ‚Ä¢ \"correct\" - game over ‚úì  ‚îÇ\n",
    "‚îÇ  ‚Ä¢ \"exit\" - quit game       ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "    ‚Üì\n",
    "Agent adjusts guess (repeat until correct)\n",
    "```\n",
    "\n",
    "### Key Architecture Components:\n",
    "\n",
    "1. **TurnManager (Custom Executor)**\n",
    "   - Coordinates game flow\n",
    "   - Handles agent responses\n",
    "   - Processes human feedback\n",
    "   - Determines game completion\n",
    "\n",
    "2. **AgentExecutor**\n",
    "   - Wraps Azure OpenAI ChatAgent\n",
    "   - Generates guesses with structured output\n",
    "   - Adjusts based on feedback\n",
    "\n",
    "3. **RequestInfoExecutor**\n",
    "   - Pauses workflow for human input\n",
    "   - Emits `RequestInfoEvent` with typed request\n",
    "   - Resumes when application provides `RequestResponse`\n",
    "   - Maintains request/response correlation\n",
    "\n",
    "### Workflow Graph:\n",
    "\n",
    "```\n",
    "TurnManager ‚îÄ(start)‚îÄ‚îÄ> AgentExecutor\n",
    "     ‚Üë                        |\n",
    "     |                   (response)\n",
    "     |                        ‚Üì\n",
    "     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ TurnManager\n",
    "                              |\n",
    "                      (request feedback)\n",
    "                              ‚Üì\n",
    "                      RequestInfoExecutor\n",
    "                              |\n",
    "                       (human response)\n",
    "                              ‚Üì\n",
    "                         TurnManager\n",
    "```\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Azure OpenAI configured with environment variables:\n",
    "  - `AZURE_OPENAI_ENDPOINT`\n",
    "  - `AZURE_OPENAI_API_VERSION`\n",
    "  - `AZURE_OPENAI_DEPLOYMENT_NAME`\n",
    "- Azure CLI authentication: `az login`\n",
    "- Agent Framework installed: `pip install agent-framework`\n",
    "- Interactive environment for human input (Jupyter notebook supports `input()`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d300211a",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd5b9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from agent_framework import (\n",
    "    AgentExecutor,  # Executor that runs the agent\n",
    "    AgentExecutorRequest,  # Message bundle sent to an AgentExecutor\n",
    "    AgentExecutorResponse,  # Result returned by an AgentExecutor\n",
    "    ChatMessage,  # Chat message structure\n",
    "    Executor,  # Base class for workflow executors\n",
    "    RequestInfoEvent,  # Event emitted when human input is requested\n",
    "    RequestInfoExecutor,  # Special executor that collects human input out of band\n",
    "    RequestInfoMessage,  # Base class for request payloads sent to RequestInfoExecutor\n",
    "    RequestResponse,  # Correlates a human response with the original request\n",
    "    Role,  # Enum of chat roles (user, assistant, system)\n",
    "    WorkflowBuilder,  # Fluent builder for assembling the graph\n",
    "    WorkflowContext,  # Per run context and event bus\n",
    "    WorkflowOutputEvent,  # Event emitted when workflow yields output\n",
    "    WorkflowRunState,  # Enum of workflow run states\n",
    "    WorkflowStatusEvent,  # Event emitted on run state changes\n",
    "    handler,  # Decorator to expose an Executor method as a step\n",
    ")\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "from azure.identity import AzureCliCredential\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv('../../.env')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0514d0bc",
   "metadata": {},
   "source": [
    "## Define Request and Response Models\n",
    "\n",
    "### HumanFeedbackRequest\n",
    "\n",
    "Subclasses `RequestInfoMessage` to define the schema for human input requests.\n",
    "\n",
    "**Why subclass RequestInfoMessage?**\n",
    "- Strong typing for request payloads\n",
    "- Forward-compatible validation\n",
    "- Clear correlation semantics\n",
    "- Attach contextual fields (e.g., agent's previous guess)\n",
    "- Rich UI rendering without extra state fetching\n",
    "\n",
    "**Fields:**\n",
    "- `prompt`: Instructions for the human\n",
    "- `guess`: Agent's last guess (provides context)\n",
    "\n",
    "### GuessOutput\n",
    "\n",
    "Pydantic model for structured agent output.\n",
    "\n",
    "**Benefits of `response_format`:**\n",
    "- Enforces JSON schema compliance\n",
    "- Eliminates regex parsing\n",
    "- Reliable, type-safe output\n",
    "- Automatic validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ead0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class HumanFeedbackRequest(RequestInfoMessage):\n",
    "    \"\"\"Request payload sent to RequestInfoExecutor for human feedback.\n",
    "    \n",
    "    Including the agent's last guess allows the UI to display context\n",
    "    and helps the turn manager avoid extra state reads.\n",
    "    \"\"\"\n",
    "    prompt: str = \"\"\n",
    "    guess: int | None = None\n",
    "\n",
    "\n",
    "class GuessOutput(BaseModel):\n",
    "    \"\"\"Structured output from the agent. Enforced via response_format for reliable parsing.\"\"\"\n",
    "    guess: int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f79176f",
   "metadata": {},
   "source": [
    "## Create TurnManager - The Game Coordinator\n",
    "\n",
    "The `TurnManager` custom executor orchestrates the entire game flow.\n",
    "\n",
    "### Handler Methods:\n",
    "\n",
    "#### 1. `start()`\n",
    "- **Trigger**: Workflow initialization with \"start\" message\n",
    "- **Action**: Send initial request to agent for first guess\n",
    "- **Output**: `AgentExecutorRequest` with user message\n",
    "\n",
    "#### 2. `on_agent_response()`\n",
    "- **Trigger**: Receives `AgentExecutorResponse` from agent\n",
    "- **Action**: \n",
    "  - Parse structured JSON output (`GuessOutput`)\n",
    "  - Create human feedback request\n",
    "  - Send `HumanFeedbackRequest` to RequestInfoExecutor\n",
    "- **Output**: Request for human to provide guidance\n",
    "\n",
    "#### 3. `on_human_feedback()`\n",
    "- **Trigger**: Receives `RequestResponse[HumanFeedbackRequest, str]` from human\n",
    "- **Action**:\n",
    "  - Process human reply (\"higher\", \"lower\", \"correct\")\n",
    "  - If \"correct\": Yield output and complete workflow\n",
    "  - If guidance: Send feedback to agent for next guess\n",
    "- **Output**: Either workflow output (game over) or next agent request\n",
    "\n",
    "### Design Pattern: Request/Response Correlation\n",
    "\n",
    "The `RequestResponse` object contains:\n",
    "- **`data`**: Human's string reply\n",
    "- **`original_request`**: The correlated `HumanFeedbackRequest`\n",
    "\n",
    "This avoids needing shared state - all context is in the message!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59631e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TurnManager(Executor):\n",
    "    \"\"\"Coordinates turns between the agent and the human.\n",
    "\n",
    "    Responsibilities:\n",
    "    - Kick off the first agent turn.\n",
    "    - After each agent reply, request human feedback with a HumanFeedbackRequest.\n",
    "    - After each human reply, either finish the game or prompt the agent again with feedback.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, id: str | None = None):\n",
    "        super().__init__(id=id or \"turn_manager\")\n",
    "\n",
    "    @handler\n",
    "    async def start(self, _: str, ctx: WorkflowContext[AgentExecutorRequest]) -> None:\n",
    "        \"\"\"Start the game by asking the agent for an initial guess.\n",
    "\n",
    "        Contract:\n",
    "        - Input is a simple starter token (ignored here).\n",
    "        - Output is an AgentExecutorRequest that triggers the agent to produce a guess.\n",
    "        \"\"\"\n",
    "        user = ChatMessage(Role.USER, text=\"Start by making your first guess.\")\n",
    "        await ctx.send_message(AgentExecutorRequest(messages=[user], should_respond=True))\n",
    "\n",
    "    @handler\n",
    "    async def on_agent_response(\n",
    "        self,\n",
    "        result: AgentExecutorResponse,\n",
    "        ctx: WorkflowContext[HumanFeedbackRequest],\n",
    "    ) -> None:\n",
    "        \"\"\"Handle the agent's guess and request human guidance.\n",
    "\n",
    "        Steps:\n",
    "        1) Parse the agent's JSON into GuessOutput for robustness.\n",
    "        2) Send a HumanFeedbackRequest to the RequestInfoExecutor with a clear instruction:\n",
    "           - higher means the human's secret number is higher than the agent's guess.\n",
    "           - lower means the human's secret number is lower than the agent's guess.\n",
    "           - correct confirms the guess is exactly right.\n",
    "           - exit quits the demo.\n",
    "        \"\"\"\n",
    "        # Parse structured model output (defensive default if the agent did not reply).\n",
    "        text = result.agent_run_response.text or \"\"\n",
    "        last_guess = GuessOutput.model_validate_json(text).guess if text else None\n",
    "\n",
    "        # Craft a precise human prompt that defines higher and lower relative to the agent's guess.\n",
    "        prompt = (\n",
    "            f\"The agent guessed: {last_guess if last_guess is not None else text}. \"\n",
    "            \"Type one of: higher (your number is higher than this guess), \"\n",
    "            \"lower (your number is lower than this guess), correct, or exit.\"\n",
    "        )\n",
    "        await ctx.send_message(HumanFeedbackRequest(prompt=prompt, guess=last_guess))\n",
    "\n",
    "    @handler\n",
    "    async def on_human_feedback(\n",
    "        self,\n",
    "        feedback: RequestResponse[HumanFeedbackRequest, str],\n",
    "        ctx: WorkflowContext[AgentExecutorRequest, str],\n",
    "    ) -> None:\n",
    "        \"\"\"Continue the game or finish based on human feedback.\n",
    "\n",
    "        The RequestResponse contains both the human's string reply and the correlated HumanFeedbackRequest,\n",
    "        which carries the prior guess for convenience.\n",
    "        \"\"\"\n",
    "        reply = (feedback.data or \"\").strip().lower()\n",
    "        # Prefer the correlated request's guess to avoid extra shared state reads.\n",
    "        last_guess = getattr(feedback.original_request, \"guess\", None)\n",
    "\n",
    "        if reply == \"correct\":\n",
    "            await ctx.yield_output(f\"Guessed correctly: {last_guess}\")\n",
    "            return\n",
    "\n",
    "        # Provide feedback to the agent to try again.\n",
    "        # We keep the agent's output strictly JSON to ensure stable parsing on the next turn.\n",
    "        user_msg = ChatMessage(\n",
    "            Role.USER,\n",
    "            text=(f'Feedback: {reply}. Return ONLY a JSON object matching the schema {{\"guess\": <int 1..10>}}.'),\n",
    "        )\n",
    "        await ctx.send_message(AgentExecutorRequest(messages=[user_msg], should_respond=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae375e64",
   "metadata": {},
   "source": [
    "## Understanding RequestInfoExecutor\n",
    "\n",
    "### What RequestInfoExecutor Does:\n",
    "\n",
    "`RequestInfoExecutor` is a **workflow-native bridge** that:\n",
    "\n",
    "1. **Pauses the workflow graph** at a request for information\n",
    "2. **Emits `RequestInfoEvent`** with a typed payload (e.g., `HumanFeedbackRequest`)\n",
    "3. **Resumes the workflow** only after application supplies matching `RequestResponse`\n",
    "4. **Maintains correlation** via `request_id` key\n",
    "\n",
    "### What RequestInfoExecutor Does NOT Do:\n",
    "\n",
    "- **Does NOT gather input itself** - Your application is responsible\n",
    "- **Does NOT have a UI** - You build the interface\n",
    "- **Does NOT store responses** - You provide them via `send_responses_streaming()`\n",
    "\n",
    "### Benefits:\n",
    "\n",
    "- **Standardizes pause-and-resume** human gating\n",
    "- **Carries typed request payloads** (via RequestInfoMessage subclasses)\n",
    "- **Preserves correlation** (request_id ‚Üí response mapping)\n",
    "- **Integrates seamlessly** with workflow graph\n",
    "\n",
    "### Request/Response Flow:\n",
    "\n",
    "```python\n",
    "# 1. Workflow emits request\n",
    "await ctx.send_message(HumanFeedbackRequest(prompt=\"...\", guess=5))\n",
    "\n",
    "# 2. RequestInfoExecutor emits RequestInfoEvent\n",
    "# event.request_id = \"req_abc123\"\n",
    "# event.data = HumanFeedbackRequest(prompt=\"...\", guess=5)\n",
    "\n",
    "# 3. Application collects human input\n",
    "human_reply = input(\"Enter higher/lower/correct: \")\n",
    "\n",
    "# 4. Application provides response\n",
    "responses = {\"req_abc123\": human_reply}\n",
    "await workflow.send_responses_streaming(responses)\n",
    "\n",
    "# 5. Workflow resumes with RequestResponse\n",
    "# feedback.data = \"higher\"\n",
    "# feedback.original_request = HumanFeedbackRequest(prompt=\"...\", guess=5)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01861c7",
   "metadata": {},
   "source": [
    "## Build the Workflow Graph\n",
    "\n",
    "### Components:\n",
    "\n",
    "1. **TurnManager**: Start executor and coordinator\n",
    "2. **AgentExecutor**: Wraps Azure OpenAI ChatAgent\n",
    "3. **RequestInfoExecutor**: Human input gateway\n",
    "\n",
    "### Edges (Message Flow):\n",
    "\n",
    "```\n",
    "TurnManager ‚Üí AgentExecutor\n",
    "  (sends AgentExecutorRequest to get guess)\n",
    "\n",
    "AgentExecutor ‚Üí TurnManager\n",
    "  (returns AgentExecutorResponse with guess)\n",
    "\n",
    "TurnManager ‚Üí RequestInfoExecutor\n",
    "  (sends HumanFeedbackRequest for guidance)\n",
    "\n",
    "RequestInfoExecutor ‚Üí TurnManager\n",
    "  (returns RequestResponse with human reply)\n",
    "```\n",
    "\n",
    "### Agent Configuration:\n",
    "\n",
    "- **`response_format=GuessOutput`**: Enforces JSON schema\n",
    "- **Instructions**: Clear guessing rules and format requirements\n",
    "- **AzureOpenAIChatClient**: Uses Azure CLI credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4681faed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the chat agent with structured output\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "chat_client = AzureOpenAIChatClient(\n",
    "    deployment_name=deployment_name,\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureCliCredential()\n",
    ")\n",
    "agent = chat_client.create_agent(\n",
    "    instructions=(\n",
    "        \"You guess a number between 1 and 10. \"\n",
    "        \"If the user says 'higher' or 'lower', adjust your next guess. \"\n",
    "        'You MUST return ONLY a JSON object exactly matching this schema: {\"guess\": <integer 1..10>}. '\n",
    "        \"No explanations or additional text.\"\n",
    "    ),\n",
    "    response_format=GuessOutput,\n",
    ")\n",
    "\n",
    "# Create workflow executors\n",
    "turn_manager = TurnManager(id=\"turn_manager\")\n",
    "agent_exec = AgentExecutor(agent=agent, id=\"agent\")\n",
    "request_info_executor = RequestInfoExecutor(id=\"request_info\")\n",
    "\n",
    "# Build the workflow graph\n",
    "workflow = (\n",
    "    WorkflowBuilder()\n",
    "    .set_start_executor(turn_manager)\n",
    "    .add_edge(turn_manager, agent_exec)  # Ask agent to make/adjust a guess\n",
    "    .add_edge(agent_exec, turn_manager)  # Agent's response comes back to coordinator\n",
    "    .add_edge(turn_manager, request_info_executor)  # Ask human for guidance\n",
    "    .add_edge(request_info_executor, turn_manager)  # Feed human guidance back to coordinator\n",
    "    .build()\n",
    ")\n",
    "\n",
    "print(\"‚úì Workflow built successfully\")\n",
    "print(\"\\nWorkflow Graph:\")\n",
    "print(\"  TurnManager (start) ‚Üí AgentExecutor\")\n",
    "print(\"  AgentExecutor ‚Üí TurnManager\")\n",
    "print(\"  TurnManager ‚Üí RequestInfoExecutor\")\n",
    "print(\"  RequestInfoExecutor ‚Üí TurnManager\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5937c7",
   "metadata": {},
   "source": [
    "## Run the Interactive Game Loop\n",
    "\n",
    "### Execution Pattern:\n",
    "\n",
    "The game uses a **streaming request/response loop**:\n",
    "\n",
    "#### First Iteration:\n",
    "```python\n",
    "stream = workflow.run_stream(\"start\")\n",
    "```\n",
    "\n",
    "#### Subsequent Iterations:\n",
    "```python\n",
    "stream = workflow.send_responses_streaming(pending_responses)\n",
    "```\n",
    "\n",
    "### Event Processing:\n",
    "\n",
    "Each iteration collects events:\n",
    "- **`RequestInfoEvent`**: Human input needed\n",
    "- **`WorkflowOutputEvent`**: Game result (completion)\n",
    "- **`WorkflowStatusEvent`**: State transitions\n",
    "\n",
    "### Workflow States:\n",
    "\n",
    "1. **`IN_PROGRESS_PENDING_REQUESTS`**: Requests are being emitted\n",
    "2. **`IDLE_WITH_PENDING_REQUESTS`**: Workflow paused, awaiting human input\n",
    "3. **Completion**: `WorkflowOutputEvent` emitted\n",
    "\n",
    "### Input Collection:\n",
    "\n",
    "For each `RequestInfoEvent`:\n",
    "1. Display prompt to human\n",
    "2. Collect response via `input()`\n",
    "3. Map `request_id` ‚Üí human response\n",
    "4. Pass to `send_responses_streaming()` in next iteration\n",
    "\n",
    "### Game Instructions:\n",
    "\n",
    "When prompted, enter one of:\n",
    "- **`higher`**: Your secret number is higher than the agent's guess\n",
    "- **`lower`**: Your secret number is lower than the agent's guess\n",
    "- **`correct`**: Agent guessed your number correctly (game ends)\n",
    "- **`exit`**: Quit the game early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa3c207",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def play_guessing_game():\n",
    "    \"\"\"Run the interactive guessing game loop.\"\"\"\n",
    "    \n",
    "    # Game state\n",
    "    pending_responses: dict[str, str] | None = None\n",
    "    completed = False\n",
    "    workflow_output: str | None = None\n",
    "\n",
    "    # User guidance\n",
    "    print(\"=\" * 70)\n",
    "    print(\"INTERACTIVE GUESSING GAME\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"Think of a number between 1 and 10.\")\n",
    "    print(\"The AI agent will try to guess it.\")\n",
    "    print(\"\\nWhen prompted, type one of:\")\n",
    "    print(\"  ‚Ä¢ higher  - Your number is HIGHER than the agent's guess\")\n",
    "    print(\"  ‚Ä¢ lower   - Your number is LOWER than the agent's guess\")\n",
    "    print(\"  ‚Ä¢ correct - Agent guessed correctly (game ends)\")\n",
    "    print(\"  ‚Ä¢ exit    - Quit the game\")\n",
    "    print(\"=\" * 70 + \"\\n\")\n",
    "\n",
    "    while not completed:\n",
    "        # First iteration uses run_stream(\"start\").\n",
    "        # Subsequent iterations use send_responses_streaming with pending_responses.\n",
    "        stream = (\n",
    "            workflow.send_responses_streaming(pending_responses) \n",
    "            if pending_responses \n",
    "            else workflow.run_stream(\"start\")\n",
    "        )\n",
    "        \n",
    "        # Collect events for this turn\n",
    "        events = [event async for event in stream]\n",
    "        pending_responses = None\n",
    "\n",
    "        # Process events\n",
    "        requests: list[tuple[str, str]] = []  # (request_id, prompt)\n",
    "        for event in events:\n",
    "            if isinstance(event, RequestInfoEvent) and isinstance(event.data, HumanFeedbackRequest):\n",
    "                # RequestInfoEvent for our HumanFeedbackRequest\n",
    "                requests.append((event.request_id, event.data.prompt))\n",
    "            elif isinstance(event, WorkflowOutputEvent):\n",
    "                # Capture workflow output as they're yielded\n",
    "                workflow_output = str(event.data)\n",
    "                completed = True\n",
    "\n",
    "        # Display workflow state transitions (for debugging/understanding)\n",
    "        pending_status = any(\n",
    "            isinstance(e, WorkflowStatusEvent) and e.state == WorkflowRunState.IN_PROGRESS_PENDING_REQUESTS\n",
    "            for e in events\n",
    "        )\n",
    "        idle_with_requests = any(\n",
    "            isinstance(e, WorkflowStatusEvent) and e.state == WorkflowRunState.IDLE_WITH_PENDING_REQUESTS\n",
    "            for e in events\n",
    "        )\n",
    "        if pending_status:\n",
    "            print(\"[State: IN_PROGRESS_PENDING_REQUESTS - requests outstanding]\")\n",
    "        if idle_with_requests:\n",
    "            print(\"[State: IDLE_WITH_PENDING_REQUESTS - awaiting human input]\\n\")\n",
    "\n",
    "        # If we have any human requests, prompt the user and prepare responses\n",
    "        if requests and not completed:\n",
    "            responses: dict[str, str] = {}\n",
    "            for req_id, prompt in requests:\n",
    "                print(f\"ü§ñ {prompt}\")\n",
    "                answer = input(\"üë§ Enter higher/lower/correct/exit: \").strip().lower()\n",
    "                \n",
    "                if answer == \"exit\":\n",
    "                    print(\"\\nüëã Exiting game...\")\n",
    "                    return\n",
    "                \n",
    "                responses[req_id] = answer\n",
    "                print()  # Blank line for readability\n",
    "            \n",
    "            pending_responses = responses\n",
    "\n",
    "    # Show final result\n",
    "    print(\"=\" * 70)\n",
    "    print(\"üéâ GAME OVER\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Result: {workflow_output}\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "\n",
    "# Run the game\n",
    "await play_guessing_game()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4c28cf",
   "metadata": {},
   "source": [
    "## Expected Output Example\n",
    "\n",
    "```\n",
    "======================================================================\n",
    "INTERACTIVE GUESSING GAME\n",
    "======================================================================\n",
    "Think of a number between 1 and 10.\n",
    "The AI agent will try to guess it.\n",
    "\n",
    "When prompted, type one of:\n",
    "  ‚Ä¢ higher  - Your number is HIGHER than the agent's guess\n",
    "  ‚Ä¢ lower   - Your number is LOWER than the agent's guess\n",
    "  ‚Ä¢ correct - Agent guessed correctly (game ends)\n",
    "  ‚Ä¢ exit    - Quit the game\n",
    "======================================================================\n",
    "\n",
    "[State: IN_PROGRESS_PENDING_REQUESTS - requests outstanding]\n",
    "[State: IDLE_WITH_PENDING_REQUESTS - awaiting human input]\n",
    "\n",
    "ü§ñ The agent guessed: 5. Type one of: higher (your number is higher than this guess), lower (your number is lower than this guess), correct, or exit.\n",
    "üë§ Enter higher/lower/correct/exit: higher\n",
    "\n",
    "[State: IN_PROGRESS_PENDING_REQUESTS - requests outstanding]\n",
    "[State: IDLE_WITH_PENDING_REQUESTS - awaiting human input]\n",
    "\n",
    "ü§ñ The agent guessed: 8. Type one of: higher (your number is higher than this guess), lower (your number is lower than this guess), correct, or exit.\n",
    "üë§ Enter higher/lower/correct/exit: higher\n",
    "\n",
    "[State: IN_PROGRESS_PENDING_REQUESTS - requests outstanding]\n",
    "[State: IDLE_WITH_PENDING_REQUESTS - awaiting human input]\n",
    "\n",
    "ü§ñ The agent guessed: 10. Type one of: higher (your number is higher than this guess), lower (your number is lower than this guess), correct, or exit.\n",
    "üë§ Enter higher/lower/correct/exit: lower\n",
    "\n",
    "[State: IN_PROGRESS_PENDING_REQUESTS - requests outstanding]\n",
    "[State: IDLE_WITH_PENDING_REQUESTS - awaiting human input]\n",
    "\n",
    "ü§ñ The agent guessed: 9. Type one of: higher (your number is higher than this guess), lower (your number is lower than this guess), correct, or exit.\n",
    "üë§ Enter higher/lower/correct/exit: correct\n",
    "\n",
    "======================================================================\n",
    "üéâ GAME OVER\n",
    "======================================================================\n",
    "Result: Guessed correctly: 9\n",
    "======================================================================\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c251882e",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### 1. Human-in-the-Loop Pattern\n",
    "\n",
    "**Core Components:**\n",
    "\n",
    "```python\n",
    "# 1. Define request schema\n",
    "@dataclass\n",
    "class HumanFeedbackRequest(RequestInfoMessage):\n",
    "    prompt: str\n",
    "    guess: int | None = None\n",
    "\n",
    "# 2. Send request in handler\n",
    "await ctx.send_message(HumanFeedbackRequest(prompt=\"...\", guess=5))\n",
    "\n",
    "# 3. Add RequestInfoExecutor to workflow\n",
    "request_info = RequestInfoExecutor(id=\"request_info\")\n",
    "builder.add_edge(turn_manager, request_info)\n",
    "builder.add_edge(request_info, turn_manager)\n",
    "\n",
    "# 4. Process RequestInfoEvent\n",
    "if isinstance(event, RequestInfoEvent):\n",
    "    request_id = event.request_id\n",
    "    prompt = event.data.prompt\n",
    "    \n",
    "# 5. Collect human input\n",
    "human_reply = input(prompt)\n",
    "\n",
    "# 6. Resume workflow\n",
    "responses = {request_id: human_reply}\n",
    "await workflow.send_responses_streaming(responses)\n",
    "```\n",
    "\n",
    "### 2. RequestInfoExecutor Capabilities\n",
    "\n",
    "| Feature | Benefit |\n",
    "|---------|--------|\n",
    "| **Typed Requests** | Strong typing via RequestInfoMessage subclasses |\n",
    "| **Correlation** | Automatic request_id ‚Üí response mapping |\n",
    "| **Context Preservation** | RequestResponse includes original request |\n",
    "| **Workflow Integration** | Standard executor, works with edges |\n",
    "| **Pause/Resume** | Clean workflow suspension mechanism |\n",
    "\n",
    "### 3. Request/Response Correlation\n",
    "\n",
    "**Why correlation matters:**\n",
    "- No shared state needed\n",
    "- Context travels with messages\n",
    "- Multiple concurrent requests supported\n",
    "- Type-safe request/response pairing\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "@handler\n",
    "async def on_human_feedback(\n",
    "    self,\n",
    "    feedback: RequestResponse[HumanFeedbackRequest, str],\n",
    "    ctx: WorkflowContext[...]\n",
    ") -> None:\n",
    "    # Access human's reply\n",
    "    reply = feedback.data  # \"higher\", \"lower\", \"correct\"\n",
    "    \n",
    "    # Access original request context\n",
    "    last_guess = feedback.original_request.guess\n",
    "    prompt = feedback.original_request.prompt\n",
    "```\n",
    "\n",
    "### 4. Structured Output with response_format\n",
    "\n",
    "**Without `response_format` (fragile):**\n",
    "```python\n",
    "# Agent might return: \"I guess 5\" or \"My guess is: 5\" or \"5\"\n",
    "text = agent_response.text\n",
    "guess = int(re.search(r'\\d+', text).group())  # Brittle regex parsing\n",
    "```\n",
    "\n",
    "**With `response_format` (reliable):**\n",
    "```python\n",
    "class GuessOutput(BaseModel):\n",
    "    guess: int\n",
    "\n",
    "agent = chat_client.create_agent(\n",
    "    instructions=\"...\",\n",
    "    response_format=GuessOutput  # Enforce schema\n",
    ")\n",
    "\n",
    "# Agent returns: {\"guess\": 5}\n",
    "output = GuessOutput.model_validate_json(agent_response.text)\n",
    "guess = output.guess  # Type-safe, validated\n",
    "```\n",
    "\n",
    "### 5. Workflow State Machine\n",
    "\n",
    "**State Transitions:**\n",
    "\n",
    "```\n",
    "START\n",
    "  ‚Üì\n",
    "IN_PROGRESS\n",
    "  ‚Üì\n",
    "IN_PROGRESS_PENDING_REQUESTS (request emitted)\n",
    "  ‚Üì\n",
    "IDLE_WITH_PENDING_REQUESTS (awaiting human)\n",
    "  ‚Üì (human provides response)\n",
    "IN_PROGRESS (resume)\n",
    "  ‚Üì\n",
    "COMPLETED (output yielded)\n",
    "```\n",
    "\n",
    "**Monitoring states:**\n",
    "```python\n",
    "for event in events:\n",
    "    if isinstance(event, WorkflowStatusEvent):\n",
    "        if event.state == WorkflowRunState.IDLE_WITH_PENDING_REQUESTS:\n",
    "            print(\"Waiting for human input...\")\n",
    "        elif event.state == WorkflowRunState.IN_PROGRESS_PENDING_REQUESTS:\n",
    "            print(\"Request being processed...\")\n",
    "```\n",
    "\n",
    "### 6. TurnManager Design Pattern\n",
    "\n",
    "**Responsibilities:**\n",
    "- **Initialize**: Start the interaction\n",
    "- **Coordinate**: Route messages between agent and human\n",
    "- **Process**: Handle responses from both parties\n",
    "- **Decide**: Determine when to continue vs. complete\n",
    "\n",
    "**Multi-handler pattern:**\n",
    "```python\n",
    "class TurnManager(Executor):\n",
    "    @handler  # Handles str input (start)\n",
    "    async def start(self, _: str, ctx: WorkflowContext[...]) -> None:\n",
    "        ...\n",
    "    \n",
    "    @handler  # Handles AgentExecutorResponse\n",
    "    async def on_agent_response(self, result: AgentExecutorResponse, ctx: WorkflowContext[...]) -> None:\n",
    "        ...\n",
    "    \n",
    "    @handler  # Handles RequestResponse[HumanFeedbackRequest, str]\n",
    "    async def on_human_feedback(self, feedback: RequestResponse[...], ctx: WorkflowContext[...]) -> None:\n",
    "        ...\n",
    "```\n",
    "\n",
    "### 7. Production HITL Implementation\n",
    "\n",
    "#### Web API Pattern\n",
    "```python\n",
    "from fastapi import FastAPI, BackgroundTasks\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# Store pending requests\n",
    "pending_requests: dict[str, dict] = {}\n",
    "\n",
    "@app.post(\"/workflow/start\")\n",
    "async def start_workflow(task: str):\n",
    "    workflow_id = generate_workflow_id()\n",
    "    # Start workflow in background\n",
    "    asyncio.create_task(run_workflow(workflow_id, task))\n",
    "    return {\"workflow_id\": workflow_id}\n",
    "\n",
    "@app.get(\"/workflow/{workflow_id}/pending\")\n",
    "async def get_pending_requests(workflow_id: str):\n",
    "    return pending_requests.get(workflow_id, [])\n",
    "\n",
    "@app.post(\"/workflow/{workflow_id}/respond\")\n",
    "async def submit_response(workflow_id: str, request_id: str, response: str):\n",
    "    await provide_response(workflow_id, {request_id: response})\n",
    "    return {\"status\": \"submitted\"}\n",
    "```\n",
    "\n",
    "#### Notification Pattern\n",
    "```python\n",
    "async def notify_user_on_request(event: RequestInfoEvent):\n",
    "    if isinstance(event.data, HumanFeedbackRequest):\n",
    "        # Send email/Slack/SMS\n",
    "        await send_notification(\n",
    "            user=\"user@company.com\",\n",
    "            subject=\"Input Required\",\n",
    "            body=event.data.prompt\n",
    "        )\n",
    "```\n",
    "\n",
    "### 8. Use Cases for Human-in-the-Loop\n",
    "\n",
    "#### Approval Workflows\n",
    "- Content review before publishing\n",
    "- Financial transaction approval\n",
    "- Data deletion confirmation\n",
    "- Model deployment gates\n",
    "\n",
    "#### Guidance and Refinement\n",
    "- Creative content iteration (this example)\n",
    "- Research direction steering\n",
    "- Report outline approval\n",
    "- Parameter tuning\n",
    "\n",
    "#### Quality Assurance\n",
    "- Data validation\n",
    "- Output verification\n",
    "- Fact checking\n",
    "- Compliance review\n",
    "\n",
    "#### Domain Expertise\n",
    "- Medical diagnosis confirmation\n",
    "- Legal document review\n",
    "- Technical specification approval\n",
    "- Safety-critical decisions\n",
    "\n",
    "### 9. Advanced Patterns\n",
    "\n",
    "#### Multi-User Approval\n",
    "```python\n",
    "@dataclass\n",
    "class ApprovalRequest(RequestInfoMessage):\n",
    "    content: str\n",
    "    required_approvers: list[str]\n",
    "    approvals_needed: int = 2\n",
    "\n",
    "@handler\n",
    "async def on_approval_response(\n",
    "    self,\n",
    "    response: RequestResponse[ApprovalRequest, dict],\n",
    "    ctx: WorkflowContext[...]\n",
    ") -> None:\n",
    "    approvals = response.data[\"approvals\"]\n",
    "    if len(approvals) >= response.original_request.approvals_needed:\n",
    "        await ctx.yield_output(\"Approved\")\n",
    "    else:\n",
    "        # Request more approvals\n",
    "        ...\n",
    "```\n",
    "\n",
    "#### Conditional Human Intervention\n",
    "```python\n",
    "@handler\n",
    "async def on_agent_response(\n",
    "    self,\n",
    "    result: AgentExecutorResponse,\n",
    "    ctx: WorkflowContext[...]\n",
    ") -> None:\n",
    "    confidence = result.metadata.get(\"confidence\", 1.0)\n",
    "    \n",
    "    if confidence < 0.7:\n",
    "        # Low confidence - request human review\n",
    "        await ctx.send_message(ReviewRequest(content=result.text))\n",
    "    else:\n",
    "        # High confidence - proceed automatically\n",
    "        await ctx.yield_output(result.text)\n",
    "```\n",
    "\n",
    "#### Timeout Handling\n",
    "```python\n",
    "import asyncio\n",
    "\n",
    "async def run_with_timeout():\n",
    "    try:\n",
    "        result = await asyncio.wait_for(\n",
    "            collect_human_response(),\n",
    "            timeout=300  # 5 minutes\n",
    "        )\n",
    "    except asyncio.TimeoutError:\n",
    "        # Use default or escalate\n",
    "        result = \"default_response\"\n",
    "```\n",
    "\n",
    "### 10. Comparison with Other Patterns\n",
    "\n",
    "| Pattern | Human Involvement | Use Case |\n",
    "|---------|------------------|----------|\n",
    "| **HITL (This Example)** | Interactive turn-taking | Iterative refinement, games |\n",
    "| **Plan Review** | Single approval point | Validate approach before execution |\n",
    "| **Checkpointing** | Resume after pause | Long-running workflows |\n",
    "| **Tool Approval** | Per-operation gates | Security, compliance |\n",
    "| **Feedback Loop** | Post-execution review | Quality assurance |\n",
    "\n",
    "### 11. Testing HITL Workflows\n",
    "\n",
    "#### Automated Testing\n",
    "```python\n",
    "import pytest\n",
    "\n",
    "@pytest.mark.asyncio\n",
    "async def test_guessing_game():\n",
    "    # Mock human responses\n",
    "    mock_responses = iter([\"higher\", \"lower\", \"correct\"])\n",
    "    \n",
    "    async def mock_input(prompt: str) -> str:\n",
    "        return next(mock_responses)\n",
    "    \n",
    "    # Run workflow with mocked input\n",
    "    result = await run_workflow_with_mock(mock_input)\n",
    "    assert \"Guessed correctly\" in result\n",
    "```\n",
    "\n",
    "#### Integration Testing\n",
    "```python\n",
    "async def test_request_response_correlation():\n",
    "    events = []\n",
    "    async for event in workflow.run_stream(\"start\"):\n",
    "        events.append(event)\n",
    "        if isinstance(event, RequestInfoEvent):\n",
    "            break\n",
    "    \n",
    "    # Verify request structure\n",
    "    request_event = events[-1]\n",
    "    assert isinstance(request_event.data, HumanFeedbackRequest)\n",
    "    assert request_event.data.guess is not None\n",
    "    \n",
    "    # Provide response\n",
    "    responses = {request_event.request_id: \"higher\"}\n",
    "    async for event in workflow.send_responses_streaming(responses):\n",
    "        # Verify response processing\n",
    "        pass\n",
    "```\n",
    "\n",
    "### 12. Best Practices Summary\n",
    "\n",
    "#### Request Design\n",
    "‚úÖ **Do:**\n",
    "- Subclass `RequestInfoMessage` for type safety\n",
    "- Include context in request (e.g., `guess` field)\n",
    "- Clear, actionable prompts\n",
    "- Validate response format\n",
    "\n",
    "‚ùå **Don't:**\n",
    "- Use generic string requests without structure\n",
    "- Rely on external state for context\n",
    "- Ambiguous instructions\n",
    "- Forget response validation\n",
    "\n",
    "#### Workflow Design\n",
    "‚úÖ **Do:**\n",
    "- Use `response_format` for structured agent output\n",
    "- Add RequestInfoExecutor edges explicitly\n",
    "- Handle all event types (RequestInfoEvent, WorkflowOutputEvent, WorkflowStatusEvent)\n",
    "- Provide clear completion conditions\n",
    "\n",
    "‚ùå **Don't:**\n",
    "- Parse agent output with regex\n",
    "- Forget to wire RequestInfoExecutor in graph\n",
    "- Ignore workflow state transitions\n",
    "- Create infinite loops without exit conditions\n",
    "\n",
    "#### Production\n",
    "‚úÖ **Do:**\n",
    "- Implement timeout handling\n",
    "- Store requests persistently\n",
    "- Send notifications for pending requests\n",
    "- Audit all human responses\n",
    "- Support multiple concurrent requests\n",
    "\n",
    "‚ùå **Don't:**\n",
    "- Block indefinitely waiting for human\n",
    "- Lose requests on server restart\n",
    "- Assume humans will respond immediately\n",
    "- Skip logging/auditing\n",
    "- Assume sequential request processing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}