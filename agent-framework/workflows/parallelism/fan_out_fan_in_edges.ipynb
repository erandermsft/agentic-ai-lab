{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b494193",
   "metadata": {},
   "source": [
    "# Fan-Out Fan-In Edges with Multi-Agent Parallelization\n",
    "\n",
    "This notebook demonstrates advanced **fan-out and fan-in patterns** using **AgentExecutor** to coordinate multiple AI agents working in parallel on the same task from different domain perspectives.\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "### Multi-Agent Parallelization\n",
    "- **Multiple AI agents** process the same prompt simultaneously\n",
    "- Each agent specializes in a different domain (research, marketing, legal)\n",
    "- **AgentExecutor** integrates Azure OpenAI for LLM-powered processing\n",
    "- Results are consolidated into a unified report\n",
    "\n",
    "### Fan-Out with Target Routing\n",
    "- `AgentExecutorRequest` includes `target_id` for agent selection\n",
    "- Dispatcher creates multiple requests, each targeting a specific agent\n",
    "- All agents receive the same prompt but apply domain-specific expertise\n",
    "\n",
    "### Fan-In with Response Aggregation\n",
    "- Collects `list[AgentExecutorResponse]` from all agents\n",
    "- Each response contains agent insights and metadata\n",
    "- Aggregator synthesizes insights into a consolidated report\n",
    "\n",
    "## Workflow Architecture\n",
    "\n",
    "```\n",
    "DispatchToExperts (creates agent requests)\n",
    "    ‚îú‚îÄ‚îÄ> researcher (AgentExecutor - research perspective)\n",
    "    ‚îú‚îÄ‚îÄ> marketer (AgentExecutor - marketing perspective)\n",
    "    ‚îî‚îÄ‚îÄ> legal (AgentExecutor - legal perspective)\n",
    "             ‚Üì\n",
    "         AggregateInsights (consolidates agent responses)\n",
    "```\n",
    "\n",
    "## What This Example Shows\n",
    "\n",
    "1. **Multi-Agent Coordination**: Parallel execution of specialized AI agents\n",
    "2. **Domain Expertise**: Each agent applies specific knowledge to the task\n",
    "3. **Response Aggregation**: Consolidating diverse perspectives into unified output\n",
    "4. **Azure OpenAI Integration**: Using AgentExecutor with cloud AI services\n",
    "5. **Event Tracing**: AgentRunEvent for observability and debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d182ab3e",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import required modules and configure Azure OpenAI credentials.\n",
    "\n",
    "### Prerequisites:\n",
    "- Azure OpenAI deployment with GPT model\n",
    "- Environment variables set:\n",
    "  - `AZURE_OPENAI_API_KEY` or `AZURE_OPENAI_ENTRA_TOKEN`\n",
    "  - `AZURE_OPENAI_ENDPOINT`\n",
    "  - `AZURE_OPENAI_DEPLOYMENT_NAME`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2160921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from agent_framework.workflows import Executor, ExecutorContext, Workflow\n",
    "from agent_framework.workflows.openai import (\n",
    "    AgentExecutor,\n",
    "    AgentExecutorRequest,\n",
    "    AgentExecutorResponse,\n",
    "    AgentRunEvent,\n",
    ")\n",
    "from azure.ai.projects.models import AzureAIClientConfiguration, ConnectionType\n",
    "from openai.types.chat import ChatCompletionMessageParam\n",
    "\n",
    "load_dotenv('../../.env')\n",
    "\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "\n",
    "# Verify Azure OpenAI configuration\n",
    "required_vars = [\"AZURE_OPENAI_ENDPOINT\", \"AZURE_OPENAI_DEPLOYMENT_NAME\"]\n",
    "missing_vars = [var for var in required_vars if not os.getenv(var)]\n",
    "\n",
    "if missing_vars:\n",
    "    print(f\"‚ö†Ô∏è  Missing environment variables: {', '.join(missing_vars)}\")\n",
    "    print(\"Please set them before running this notebook.\")\n",
    "else:\n",
    "    print(\"‚úÖ Azure OpenAI configuration found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed78c66",
   "metadata": {},
   "source": [
    "## Define Message Types\n",
    "\n",
    "We'll use dataclasses to represent the workflow messages:\n",
    "\n",
    "- **`Prompt`**: The user's question or task\n",
    "- **`ConsolidatedReport`**: Aggregated insights from all agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bff56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Prompt:\n",
    "    \"\"\"User prompt to be analyzed by multiple agents.\"\"\"\n",
    "    text: str\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ConsolidatedReport:\n",
    "    \"\"\"Consolidated insights from all domain expert agents.\"\"\"\n",
    "    insights: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6f65e5",
   "metadata": {},
   "source": [
    "## Dispatcher Executor\n",
    "\n",
    "The **DispatchToExperts** executor creates agent requests for each domain expert.\n",
    "\n",
    "### Key Features:\n",
    "- Converts prompt into `AgentExecutorRequest` objects\n",
    "- Each request targets a specific agent via `target_id`\n",
    "- All requests contain the same user prompt\n",
    "- Fan-out ensures parallel agent execution\n",
    "\n",
    "### Agent Targeting:\n",
    "- `target_id=\"researcher\"` ‚Üí Research agent\n",
    "- `target_id=\"marketer\"` ‚Üí Marketing agent\n",
    "- `target_id=\"legal\"` ‚Üí Legal agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6994a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DispatchToExperts(Executor[Prompt, AgentExecutorRequest]):\n",
    "    \"\"\"Dispatches the prompt to multiple domain expert agents in parallel.\"\"\"\n",
    "\n",
    "    async def execute(self, ctx: ExecutorContext[Prompt]) -> AgentExecutorRequest:\n",
    "        prompt = ctx.get_input_data().text\n",
    "        print(f\"\\nüìã Dispatching prompt to domain experts: '{prompt}'\\n\")\n",
    "\n",
    "        # Create request with the user prompt\n",
    "        messages: list[ChatCompletionMessageParam] = [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "\n",
    "        # Return request - target_id will be set by fan-out routing\n",
    "        return AgentExecutorRequest(messages=messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3f2131",
   "metadata": {},
   "source": [
    "## Domain Expert Agents\n",
    "\n",
    "We'll create three **AgentExecutor** instances, each with domain-specific instructions.\n",
    "\n",
    "### Agent Roles:\n",
    "\n",
    "1. **Researcher Agent** (`id=\"researcher\"`)\n",
    "   - Analyzes from academic and research perspective\n",
    "   - Focuses on data, evidence, and scholarly insights\n",
    "\n",
    "2. **Marketer Agent** (`id=\"marketer\"`)\n",
    "   - Evaluates from marketing and business perspective\n",
    "   - Focuses on audience, positioning, and market impact\n",
    "\n",
    "3. **Legal Agent** (`id=\"legal\"`)\n",
    "   - Reviews from legal and compliance perspective\n",
    "   - Identifies risks, regulations, and legal considerations\n",
    "\n",
    "### AgentExecutor Configuration:\n",
    "- Uses Azure OpenAI for LLM inference\n",
    "- System instructions define agent expertise\n",
    "- Unique `id` enables targeted routing\n",
    "- Handles `AgentExecutorRequest` ‚Üí `AgentExecutorResponse` transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532b0638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Azure OpenAI client\n",
    "client_config = AzureAIClientConfiguration(\n",
    "    endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    type=ConnectionType.AZURE_OPEN_AI,\n",
    ")\n",
    "\n",
    "model = os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"]\n",
    "\n",
    "# Create domain expert agents\n",
    "researcher = AgentExecutor(\n",
    "    id=\"researcher\",\n",
    "    client_config=client_config,\n",
    "    model=model,\n",
    "    instructions=\"You are a research expert. Analyze the prompt from an academic and research perspective. Provide data-driven insights.\",\n",
    ")\n",
    "\n",
    "marketer = AgentExecutor(\n",
    "    id=\"marketer\",\n",
    "    client_config=client_config,\n",
    "    model=model,\n",
    "    instructions=\"You are a marketing expert. Analyze the prompt from a marketing and business perspective. Focus on audience and market impact.\",\n",
    ")\n",
    "\n",
    "legal = AgentExecutor(\n",
    "    id=\"legal\",\n",
    "    client_config=client_config,\n",
    "    model=model,\n",
    "    instructions=\"You are a legal expert. Analyze the prompt from a legal and compliance perspective. Identify risks and regulations.\",\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Domain expert agents created:\")\n",
    "print(\"   - Researcher (academic perspective)\")\n",
    "print(\"   - Marketer (business perspective)\")\n",
    "print(\"   - Legal (compliance perspective)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699f5517",
   "metadata": {},
   "source": [
    "## Aggregator Executor\n",
    "\n",
    "The **AggregateInsights** executor consolidates responses from all domain experts.\n",
    "\n",
    "### Key Features:\n",
    "- Receives `list[AgentExecutorResponse]` from parallel agents\n",
    "- Extracts text insights from each response\n",
    "- Identifies agent source from response metadata\n",
    "- Creates unified report with all perspectives\n",
    "\n",
    "### Response Processing:\n",
    "- Iterates through agent responses in order\n",
    "- Extracts agent name from `target_id`\n",
    "- Formats insights with clear attribution\n",
    "- Combines into readable consolidated report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f76bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AggregateInsights(Executor[list[AgentExecutorResponse], ConsolidatedReport]):\n",
    "    \"\"\"Aggregates insights from all domain expert agents.\"\"\"\n",
    "\n",
    "    async def execute(\n",
    "        self, ctx: ExecutorContext[list[AgentExecutorResponse]]\n",
    "    ) -> ConsolidatedReport:\n",
    "        responses = ctx.get_input_data()\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"AGGREGATING INSIGHTS FROM DOMAIN EXPERTS\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "        insights_text = []\n",
    "\n",
    "        for response in responses:\n",
    "            agent_name = response.request.target_id or \"Unknown\"\n",
    "            insight = response.messages[-1].get(\"content\", \"\") if response.messages else \"No response\"\n",
    "\n",
    "            print(f\"üîç {agent_name.upper()} PERSPECTIVE:\")\n",
    "            print(f\"{insight}\\n\")\n",
    "            print(\"-\" * 60 + \"\\n\")\n",
    "\n",
    "            insights_text.append(f\"**{agent_name.capitalize()} Perspective:**\\n{insight}\")\n",
    "\n",
    "        # Create consolidated report\n",
    "        consolidated = \"\\n\\n\".join(insights_text)\n",
    "\n",
    "        print(\"\\n‚úÖ All insights consolidated\\n\")\n",
    "        return ConsolidatedReport(insights=consolidated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2323c6c8",
   "metadata": {},
   "source": [
    "## Build the Workflow\n",
    "\n",
    "Construct the multi-agent workflow with fan-out and fan-in edges.\n",
    "\n",
    "### Workflow Construction Steps:\n",
    "\n",
    "1. **Create executor instances** (dispatcher, agents, aggregator)\n",
    "2. **Add fan-out edges** from DispatchToExperts to all three agents\n",
    "   - Automatically routes `AgentExecutorRequest` to matching `target_id`\n",
    "3. **Add fan-in edges** from all agents to AggregateInsights\n",
    "   - Collects `list[AgentExecutorResponse]` in order\n",
    "4. **Set entry point** to DispatchToExperts\n",
    "\n",
    "### Graph Visualization:\n",
    "```\n",
    "      DispatchToExperts\n",
    "      /       |       \\\n",
    " researcher marketer legal\n",
    "      \\       |       /\n",
    "      AggregateInsights\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d48ed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create executor instances\n",
    "dispatcher = DispatchToExperts()\n",
    "aggregator = AggregateInsights()\n",
    "\n",
    "# Build the workflow\n",
    "workflow = Workflow()\n",
    "\n",
    "# Fan out from dispatcher to all domain expert agents\n",
    "workflow.add_fan_out_edges(dispatcher, [researcher, marketer, legal])\n",
    "\n",
    "# Fan in from all agents to aggregator\n",
    "workflow.add_fan_in_edges([researcher, marketer, legal], aggregator)\n",
    "\n",
    "# Set the entry point\n",
    "workflow.set_entry_point(dispatcher)\n",
    "\n",
    "print(\"‚úÖ Multi-agent workflow constructed successfully!\")\n",
    "print(\"\\nGraph structure:\")\n",
    "print(\"  DispatchToExperts ‚Üí [researcher, marketer, legal] ‚Üí AggregateInsights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2ab475",
   "metadata": {},
   "source": [
    "## Run the Workflow\n",
    "\n",
    "Execute the workflow with a sample prompt and observe multi-agent collaboration.\n",
    "\n",
    "### Expected Behavior:\n",
    "1. Dispatcher sends prompt to all three agents\n",
    "2. Agents process in parallel using Azure OpenAI\n",
    "3. Each agent applies domain-specific expertise\n",
    "4. Aggregator consolidates all perspectives\n",
    "5. Final report includes research, marketing, and legal insights\n",
    "\n",
    "### Note on Execution:\n",
    "- Agents may complete in any order (parallel execution)\n",
    "- Network latency affects individual agent completion time\n",
    "- Framework ensures all agents complete before aggregation\n",
    "- Event tracing via `AgentRunEvent` enables debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d874a8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt\n",
    "user_prompt = \"What are the implications of implementing AI-powered customer service chatbots?\"\n",
    "\n",
    "# Run the workflow\n",
    "result = await workflow.run(Prompt(text=user_prompt))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL CONSOLIDATED REPORT\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "print(result.insights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef27055",
   "metadata": {},
   "source": [
    "## Event Tracing with AgentRunEvent\n",
    "\n",
    "The Agent Framework emits **AgentRunEvent** objects during execution for observability.\n",
    "\n",
    "### Event Types:\n",
    "- **`agent.run.started`**: Agent begins processing\n",
    "- **`agent.run.completed`**: Agent finishes successfully\n",
    "- **`agent.run.failed`**: Agent encounters error\n",
    "\n",
    "### Event Data:\n",
    "- `agent_id`: Which agent emitted the event\n",
    "- `timestamp`: When the event occurred\n",
    "- `request`: The input AgentExecutorRequest\n",
    "- `response`: The output AgentExecutorResponse (if completed)\n",
    "- `error`: Exception details (if failed)\n",
    "\n",
    "### Use Cases:\n",
    "- Debugging agent execution issues\n",
    "- Performance monitoring and optimization\n",
    "- Audit trails for compliance\n",
    "- Real-time progress tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f90b44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Accessing event data programmatically\n",
    "# (Events are automatically emitted during workflow execution)\n",
    "\n",
    "print(\"\\nüìä Agent Execution Events:\")\n",
    "print(\"   - Events are emitted during workflow.run()\")\n",
    "print(\"   - Use event handlers to capture and process events\")\n",
    "print(\"   - Enable telemetry for distributed tracing\")\n",
    "print(\"   - Integrate with Azure Monitor or Application Insights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbfc5bd",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### Multi-Agent Parallelization\n",
    "- ‚úÖ **Domain Expertise**: Each agent specializes in specific knowledge area\n",
    "- ‚úÖ **Parallel Execution**: All agents process simultaneously for efficiency\n",
    "- ‚úÖ **Diverse Perspectives**: Multiple viewpoints enrich the analysis\n",
    "- ‚úÖ **Consolidated Output**: Unified report combines all insights\n",
    "\n",
    "### Fan-Out with AgentExecutor\n",
    "- ‚úÖ **Target Routing**: `target_id` directs requests to specific agents\n",
    "- ‚úÖ **Shared Prompt**: Same input analyzed from different angles\n",
    "- ‚úÖ **Independent Processing**: Agents don't interfere with each other\n",
    "- ‚úÖ **Scalable Pattern**: Easy to add more domain experts\n",
    "\n",
    "### Fan-In with Response Aggregation\n",
    "- ‚úÖ **Type-Safe Collection**: `list[AgentExecutorResponse]` ensures consistency\n",
    "- ‚úÖ **Ordered Results**: Responses collected in edge definition order\n",
    "- ‚úÖ **Metadata Preservation**: Agent identity and request context maintained\n",
    "- ‚úÖ **Flexible Aggregation**: Custom logic for combining insights\n",
    "\n",
    "### Azure OpenAI Integration\n",
    "- ‚úÖ **Enterprise-Ready**: Cloud-based LLM inference\n",
    "- ‚úÖ **Configuration Management**: Environment variables for credentials\n",
    "- ‚úÖ **Model Selection**: Specify deployment names for different models\n",
    "- ‚úÖ **System Instructions**: Define agent behavior and expertise\n",
    "\n",
    "### Observability and Debugging\n",
    "- ‚úÖ **Event Tracing**: `AgentRunEvent` for execution monitoring\n",
    "- ‚úÖ **Error Handling**: Automatic failure detection and reporting\n",
    "- ‚úÖ **Performance Tracking**: Measure agent execution times\n",
    "- ‚úÖ **Audit Trails**: Record all agent interactions\n",
    "\n",
    "### When to Use This Pattern\n",
    "- ‚úÖ Need diverse expert perspectives on the same problem\n",
    "- ‚úÖ Complex analysis requiring multiple knowledge domains\n",
    "- ‚úÖ Want to parallelize AI agent processing for speed\n",
    "- ‚úÖ Building multi-agent systems with specialized roles\n",
    "- ‚úÖ Require consolidated reporting from distributed agents\n",
    "\n",
    "### Best Practices\n",
    "- üéØ **Define Clear Roles**: Give each agent specific expertise\n",
    "- üéØ **Use System Instructions**: Guide agent behavior with prompts\n",
    "- üéØ **Handle Failures Gracefully**: Implement error recovery strategies\n",
    "- üéØ **Monitor Performance**: Track agent execution times and costs\n",
    "- üéØ **Validate Credentials**: Check environment variables before execution\n",
    "- üéØ **Aggregate Thoughtfully**: Preserve attribution and context in reports\n",
    "\n",
    "### Next Steps\n",
    "- Add more domain experts (financial, technical, ethical, etc.)\n",
    "- Implement dynamic agent selection based on prompt analysis\n",
    "- Add retry logic for failed agent executions\n",
    "- Integrate with Azure Monitor for production telemetry\n",
    "- Experiment with different LLM models for each agent\n",
    "- Build a web interface for interactive multi-agent consultation"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
