{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "884bd215",
   "metadata": {},
   "source": [
    "# Azure AI Agent Observability with Application Insights\n",
    "\n",
    "This notebook demonstrates how to enable observability for Azure AI agents using **OpenTelemetry** and **Azure Application Insights**. Agent Framework integrates with OpenTelemetry and emits traces, logs, and metrics according to the [OpenTelemetry GenAI Semantic Conventions](https://opentelemetry.io/docs/specs/semconv/gen-ai/).\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- ‚úÖ How to set up **automatic telemetry** for Azure AI agents\n",
    "- ‚úÖ How to configure **Application Insights** connection\n",
    "- ‚úÖ How to **trace agent invocations** and tool calls\n",
    "- ‚úÖ How to view **trace IDs** for debugging\n",
    "- ‚úÖ How to enable **streaming responses** with observability\n",
    "\n",
    "## Key Observability Features\n",
    "\n",
    "### Automatic Spans Created\n",
    "- **`invoke_agent <agent_name>`**: Top-level span for each agent invocation\n",
    "- **`chat <model_name>`**: Span for underlying chat model calls\n",
    "- **`execute_tool <function_name>`**: Span for function tool executions\n",
    "\n",
    "### Metrics Collected\n",
    "- **`gen_ai.client.operation.duration`** (histogram): Operation duration in seconds\n",
    "- **`gen_ai.client.token.usage`** (histogram): Token usage counts\n",
    "- **`agent_framework.function.invocation.duration`** (histogram): Function execution duration\n",
    "\n",
    "> **Note**: You must add an **Application Insights** instance to your Azure AI project for this sample to work. The `setup_azure_ai_observability()` method automatically retrieves the connection string from your Azure AI project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a44c46",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, ensure you have:\n",
    "\n",
    "1. **Application Insights** attached to your Azure AI Foundry project\n",
    "2. **Azure CLI** authenticated (`az login --use-device-code`)\n",
    "3. **Environment variables** configured in `../.env`:\n",
    "   - `AZURE_AI_PROJECT_ENDPOINT`\n",
    "4. **Python packages** installed:\n",
    "   ```bash\n",
    "   pip install agent-framework agent-framework-azure-ai python-dotenv azure-identity\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b9f119",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "We'll import the necessary libraries for agent creation, Azure AI integration, and observability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea3ed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft. All rights reserved.\n",
    "\n",
    "import asyncio\n",
    "import os\n",
    "from random import randint\n",
    "from typing import Annotated\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import Field\n",
    "\n",
    "from agent_framework import ChatAgent\n",
    "from agent_framework.azure import AzureAIAgentClient\n",
    "from agent_framework.observability import get_tracer\n",
    "from azure.ai.projects.aio import AIProjectClient\n",
    "from azure.identity.aio import AzureCliCredential\n",
    "from opentelemetry.trace import SpanKind\n",
    "from opentelemetry.trace.span import format_trace_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da29455",
   "metadata": {},
   "source": [
    "## Environment Configuration\n",
    "\n",
    "Load environment variables from the parent directory's `.env` file. We need the Azure AI project endpoint to connect to Azure AI Foundry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327605cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from parent directory\n",
    "load_dotenv('../.env')\n",
    "\n",
    "# Validate required environment variable\n",
    "required_vars = ['AZURE_AI_PROJECT_ENDPOINT']\n",
    "missing = [var for var in required_vars if not os.getenv(var)]\n",
    "\n",
    "if missing:\n",
    "    raise RuntimeError(f'Missing required environment variables: {missing}')\n",
    "\n",
    "endpoint = os.getenv('AZURE_AI_PROJECT_ENDPOINT')\n",
    "print(f'‚úÖ AZURE_AI_PROJECT_ENDPOINT: {endpoint}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dabf9c0",
   "metadata": {},
   "source": [
    "## Define Function Tools\n",
    "\n",
    "We'll create a simple weather function that the agent can call. This demonstrates how tool calls are also traced in the observability system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1c0cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_weather(\n",
    "    location: Annotated[str, Field(description=\"The location to get the weather for.\")],\n",
    ") -> str:\n",
    "    \"\"\"Get the weather for a given location.\"\"\"\n",
    "    # Simulate a network call\n",
    "    await asyncio.sleep(randint(0, 10) / 10.0)\n",
    "    \n",
    "    conditions = [\"sunny\", \"cloudy\", \"rainy\", \"stormy\"]\n",
    "    temperature = randint(10, 30)\n",
    "    weather_condition = conditions[randint(0, 3)]\n",
    "    \n",
    "    return f\"The weather in {location} is {weather_condition} with a high of {temperature}¬∞C.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa377a0",
   "metadata": {},
   "source": [
    "## Understanding Azure AI Observability Setup\n",
    "\n",
    "### How Observability Works\n",
    "\n",
    "1. **Automatic Connection**: The `setup_azure_ai_observability()` method automatically retrieves the Application Insights connection string from your Azure AI project.\n",
    "\n",
    "2. **Global Configuration**: This sets up the global OpenTelemetry tracer and meter providers, which will automatically track:\n",
    "   - Agent invocations\n",
    "   - Chat model calls\n",
    "   - Tool executions\n",
    "   - Token usage\n",
    "   - Response times\n",
    "\n",
    "3. **Trace IDs**: Each conversation gets a unique trace ID that can be used to find all related spans in Application Insights.\n",
    "\n",
    "### Viewing Traces in Azure\n",
    "\n",
    "After running this notebook:\n",
    "1. Go to Azure Portal ‚Üí Your Azure AI Foundry Project\n",
    "2. Navigate to the connected Application Insights resource\n",
    "3. Go to **Transaction Search** or **End-to-end transaction details**\n",
    "4. Search for the trace ID printed in the output\n",
    "5. View the complete trace timeline with all spans and metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac0d299",
   "metadata": {},
   "source": [
    "## Main Demo: Agent with Observability\n",
    "\n",
    "This demo shows:\n",
    "- Creating an Azure AI agent with observability enabled\n",
    "- Using streaming responses\n",
    "- Automatic trace collection for agent and tool calls\n",
    "- Getting a trace ID for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccffbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_agent_with_observability():\n",
    "    \"\"\"\n",
    "    Run an Azure AI agent with observability enabled.\n",
    "    \n",
    "    This demonstrates:\n",
    "    - Automatic Application Insights integration\n",
    "    - Trace ID generation for debugging\n",
    "    - Streaming responses with telemetry\n",
    "    - Function tool execution tracing\n",
    "    \"\"\"\n",
    "    # Create async context managers for Azure resources\n",
    "    async with (\n",
    "        AzureCliCredential() as credential,\n",
    "        AIProjectClient(endpoint=endpoint, credential=credential) as project,\n",
    "        AzureAIAgentClient(project_client=project) as client,\n",
    "    ):\n",
    "        # Enable observability - this configures the application to send telemetry \n",
    "        # to the Application Insights instance attached to the Azure AI project\n",
    "        print(\"üîß Setting up Azure AI observability...\")\n",
    "        await client.setup_azure_ai_observability()\n",
    "        print(\"‚úÖ Observability configured\\n\")\n",
    "        \n",
    "        # Test questions - mix of weather queries and general knowledge\n",
    "        questions = [\n",
    "            \"What's the weather in Amsterdam?\",\n",
    "            \"and in Paris, and which is better?\",\n",
    "            \"Why is the sky blue?\"\n",
    "        ]\n",
    "        \n",
    "        # Create a custom span to group all agent interactions\n",
    "        # This is optional but helpful for grouping related operations\n",
    "        with get_tracer().start_as_current_span(\n",
    "            \"Single Agent Chat\", \n",
    "            kind=SpanKind.CLIENT\n",
    "        ) as current_span:\n",
    "            # Get and display the trace ID - you can use this to find traces in Application Insights\n",
    "            trace_id = format_trace_id(current_span.get_span_context().trace_id)\n",
    "            print(\"=\"*70)\n",
    "            print(f\"üîç Trace ID: {trace_id}\")\n",
    "            print(f\"   Use this ID to find traces in Application Insights\")\n",
    "            print(\"=\"*70)\n",
    "            print()\n",
    "            \n",
    "            # Create the agent with tools\n",
    "            agent = ChatAgent(\n",
    "                chat_client=client,\n",
    "                tools=get_weather,\n",
    "                name=\"WeatherAgent\",\n",
    "                instructions=\"You are a weather assistant.\",\n",
    "            )\n",
    "            \n",
    "            # Create a thread for the conversation\n",
    "            thread = agent.get_new_thread()\n",
    "            \n",
    "            # Process each question with streaming response\n",
    "            for question in questions:\n",
    "                print(f\"üë§ User: {question}\")\n",
    "                print(f\"ü§ñ {agent.display_name}: \", end=\"\")\n",
    "                \n",
    "                # Stream the response (telemetry is automatically collected)\n",
    "                async for update in agent.run_stream(question, thread=thread):\n",
    "                    if update.text:\n",
    "                        print(update.text, end=\"\", flush=True)\n",
    "                \n",
    "                print(\"\\n\")  # New line after response\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "        print(\"‚úÖ Demo completed!\")\n",
    "        print(f\"   Check Application Insights for trace ID: {trace_id}\")\n",
    "        print(\"=\"*70)\n",
    "\n",
    "# Run the demo\n",
    "await run_agent_with_observability()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828934a5",
   "metadata": {},
   "source": [
    "## üîç How to Find Traces in Azure AI Foundry\n",
    "\n",
    "After running the cell below, follow these **exact steps** to find your traces:\n",
    "\n",
    "### Method 1: Azure AI Foundry Studio (Recommended)\n",
    "\n",
    "1. **Open**: https://ai.azure.com\n",
    "2. **Sign in** with your Azure account\n",
    "3. **Click** on your project: **kd-foundry-project** (or select from the list)\n",
    "4. **Look for \"Tracing\"** in the left navigation menu\n",
    "   - It should be under the \"Monitoring\" or \"Evaluate\" section\n",
    "   - If you don't see it, click on \"...\" (More) or check under different menu sections\n",
    "5. **Wait 1-2 minutes**, then **refresh** the page\n",
    "6. **Search** for the trace ID shown in the output below\n",
    "7. **Click** on the trace to see the full hierarchy\n",
    "\n",
    "### Method 2: Application Insights in Azure Portal\n",
    "\n",
    "1. **Open**: https://portal.azure.com\n",
    "2. **Search** for: `kd-foundry-project` in the top search bar\n",
    "3. **Find the Application Insights resource** (it might be named like `kd-foundry-project-appinsights` or similar)\n",
    "4. **Click** on the Application Insights resource\n",
    "5. On the left menu, find **\"Transaction search\"** (under \"Investigate\")\n",
    "6. **Set time range** to \"Last 1 hour\" or \"Last 6 hours\"\n",
    "7. **Click** \"Search\" to see all recent transactions\n",
    "8. **Look for** operations with names like:\n",
    "   - `invoke_agent WeatherAgent`\n",
    "   - `chat gpt-4o`\n",
    "   - `execute_tool get_weather`\n",
    "9. **Click** on any transaction to see the full trace\n",
    "\n",
    "### What Traces Look Like\n",
    "\n",
    "You should see a hierarchy like this:\n",
    "```\n",
    "Single Agent Chat (root span)\n",
    "‚îî‚îÄ‚îÄ invoke_agent WeatherAgent\n",
    "    ‚îú‚îÄ‚îÄ chat gpt-4o\n",
    "    ‚îî‚îÄ‚îÄ execute_tool get_weather\n",
    "```\n",
    "\n",
    "> **‚è±Ô∏è Note**: Traces can take 1-5 minutes to appear. If you don't see them immediately, wait and refresh!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7154bde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: Get Application Insights Information\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "print(\"üìã Your Azure Configuration:\")\n",
    "print(f\"  Subscription ID: {os.getenv('AZURE_SUBSCRIPTION_ID')}\")\n",
    "print(f\"  Resource Group: {os.getenv('AZURE_RESOURCE_GROUP')}\")\n",
    "print(f\"  Project Name: {os.getenv('AZURE_PROJECT_NAME')}\")\n",
    "print()\n",
    "print(\"üîó Direct Links:\")\n",
    "print(f\"  Azure AI Foundry: https://ai.azure.com\")\n",
    "print(f\"  Azure Portal (Resource Group): https://portal.azure.com/#@{os.getenv('TENANT_ID')}/resource/subscriptions/{os.getenv('AZURE_SUBSCRIPTION_ID')}/resourceGroups/{os.getenv('AZURE_RESOURCE_GROUP')}/overview\")\n",
    "print()\n",
    "print(\"üìù To find Application Insights:\")\n",
    "print(\"  1. Go to Azure Portal link above\")\n",
    "print(\"  2. Look for a resource with type 'Application Insights'\")\n",
    "print(\"  3. Click on it and go to 'Transaction search'\")\n",
    "print(\"  4. Set time range to 'Last 1 hour'\")\n",
    "print(\"  5. Look for traces with 'invoke_agent' or 'WeatherAgent'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e9ad2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic: Check Application Insights Connection\n",
    "async def check_app_insights_connection():\n",
    "    \"\"\"Check which Application Insights instance is configured for the AI project.\"\"\"\n",
    "    from azure.identity.aio import AzureCliCredential\n",
    "    from azure.ai.projects.aio import AIProjectClient\n",
    "    import os\n",
    "    from dotenv import load_dotenv\n",
    "    \n",
    "    load_dotenv(\"../.env\")\n",
    "    endpoint = os.getenv(\"AZURE_AI_PROJECT_ENDPOINT\")\n",
    "    \n",
    "    async with (\n",
    "        AzureCliCredential() as credential,\n",
    "        AIProjectClient(endpoint=endpoint, credential=credential) as project,\n",
    "    ):\n",
    "        # Try to get project properties\n",
    "        print(\"üîç Checking Azure AI Project Configuration...\")\n",
    "        print(f\"   Project Endpoint: {endpoint}\")\n",
    "        \n",
    "        # The AIProjectClient should have connection information\n",
    "        try:\n",
    "            # Get the project's properties which should include App Insights\n",
    "            print(\"\\n‚úÖ Successfully connected to Azure AI Project\")\n",
    "            print(\"   If observability is working, traces should appear in Application Insights\")\n",
    "            print(\"\\nüìù Next steps:\")\n",
    "            print(\"   1. Run the agent demo cell above\")\n",
    "            print(\"   2. Wait 2-3 minutes\")\n",
    "            print(\"   3. Check Application Insights in Azure Portal\")\n",
    "            print(\"   4. Look for traces with the trace ID shown in the output\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Error: {e}\")\n",
    "\n",
    "await check_app_insights_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b3bd2f",
   "metadata": {},
   "source": [
    "## Understanding the Telemetry Data\n",
    "\n",
    "### What Gets Tracked\n",
    "\n",
    "When you run the agent above, Application Insights captures:\n",
    "\n",
    "1. **Agent Invocation Span** (`invoke_agent WeatherAgent`):\n",
    "   - Duration of the entire agent operation\n",
    "   - Input instructions\n",
    "   - Response metadata\n",
    "   - Token usage (input and output)\n",
    "\n",
    "2. **Chat Model Span** (`chat <model_name>`):\n",
    "   - LLM invocation details\n",
    "   - Model name and system used\n",
    "   - Response ID for correlation\n",
    "\n",
    "3. **Tool Execution Span** (`execute_tool get_weather`):\n",
    "   - Function execution duration\n",
    "   - Function arguments (if sensitive data is enabled)\n",
    "   - Function results (if sensitive data is enabled)\n",
    "\n",
    "### Sample Trace Output\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"name\": \"invoke_agent WeatherAgent\",\n",
    "    \"trace_id\": \"0xf2258b51421fe9cf4c0bd428c87b1ae4\",\n",
    "    \"span_id\": \"0x2cad6fc139dcf01d\",\n",
    "    \"attributes\": {\n",
    "        \"gen_ai.operation.name\": \"invoke_agent\",\n",
    "        \"gen_ai.system\": \"openai\",\n",
    "        \"gen_ai.agent.id\": \"WeatherAgent\",\n",
    "        \"gen_ai.agent.name\": \"WeatherAgent\",\n",
    "        \"gen_ai.request.instructions\": \"You are a weather assistant.\",\n",
    "        \"gen_ai.usage.input_tokens\": 26,\n",
    "        \"gen_ai.usage.output_tokens\": 29\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77689d7",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "### Enable Sensitive Data Logging (Development Only)\n",
    "\n",
    "To see actual prompts, responses, and function arguments in traces, set environment variables:\n",
    "\n",
    "```bash\n",
    "ENABLE_SENSITIVE_DATA=true\n",
    "```\n",
    "\n",
    "Then use:\n",
    "```python\n",
    "from agent_framework.observability import setup_observability\n",
    "setup_observability(enable_sensitive_data=True)\n",
    "```\n",
    "\n",
    "‚ö†Ô∏è **Warning**: Only enable in development! This may expose sensitive user data in logs.\n",
    "\n",
    "### Explore More Observability Features\n",
    "\n",
    "1. **View traces in Azure Portal**: Use the trace ID to find your traces\n",
    "2. **Create custom spans**: Use `get_tracer()` to add your own spans\n",
    "3. **Add custom metrics**: Use `get_meter()` to track custom metrics\n",
    "4. **Try Aspire Dashboard**: For local development visualization\n",
    "\n",
    "### Related Documentation\n",
    "\n",
    "- üìñ [Agent Observability Guide](https://learn.microsoft.com/en-us/agent-framework/user-guide/agents/agent-observability?pivots=programming-language-python)\n",
    "- üìñ [OpenTelemetry GenAI Conventions](https://opentelemetry.io/docs/specs/semconv/gen-ai/)\n",
    "- üìñ [Application Insights](https://learn.microsoft.com/en-us/azure/azure-monitor/app/app-insights-overview)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
